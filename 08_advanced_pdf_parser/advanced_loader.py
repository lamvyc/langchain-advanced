"""
é«˜çº§ PDF åŠ è½½å™¨
æ•´åˆè¡¨æ ¼æå–ã€OCR è¯†åˆ«ã€ç‰ˆé¢åˆ†æï¼Œæä¾›ç»Ÿä¸€çš„åŠ è½½æ¥å£
"""

from typing import List, Dict, Optional
from pathlib import Path
import logging

from table_extractor import TableExtractor
from image_ocr import ImageOCR
from layout_analyzer import LayoutAnalyzer

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AdvancedPDFLoader:
    """é«˜çº§ PDF åŠ è½½å™¨"""
    
    def __init__(self, 
                 enable_table_extraction: bool = True,
                 enable_ocr: bool = True,
                 enable_layout_analysis: bool = True,
                 ocr_lang: str = 'ch'):
        """
        åˆå§‹åŒ–é«˜çº§åŠ è½½å™¨
        
        Args:
            enable_table_extraction: æ˜¯å¦å¯ç”¨è¡¨æ ¼æå–
            enable_ocr: æ˜¯å¦å¯ç”¨ OCR
            enable_layout_analysis: æ˜¯å¦å¯ç”¨ç‰ˆé¢åˆ†æ
            ocr_lang: OCR è¯­è¨€ï¼ˆ'ch': ä¸­æ–‡, 'en': è‹±æ–‡ï¼‰
        """
        self.enable_table_extraction = enable_table_extraction
        self.enable_ocr = enable_ocr
        self.enable_layout_analysis = enable_layout_analysis
        
        # åˆå§‹åŒ–å„æ¨¡å—
        if enable_table_extraction:
            self.table_extractor = TableExtractor()
            logger.info("âœ… è¡¨æ ¼æå–æ¨¡å—å·²åŠ è½½")
        
        if enable_ocr:
            self.ocr = ImageOCR(lang=ocr_lang)
            logger.info("âœ… OCR æ¨¡å—å·²åŠ è½½")
        
        if enable_layout_analysis:
            self.layout_analyzer = LayoutAnalyzer()
            logger.info("âœ… ç‰ˆé¢åˆ†ææ¨¡å—å·²åŠ è½½")
    
    def load(self, pdf_path: str) -> Dict:
        """
        åŠ è½½å¹¶è§£æ PDF æ–‡æ¡£
        
        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            
        Returns:
            è§£æç»“æœå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - text: æ–‡æœ¬å†…å®¹ï¼ˆæŒ‰é˜…è¯»é¡ºåºï¼‰
            - tables: æå–çš„è¡¨æ ¼åˆ—è¡¨
            - ocr_results: OCR è¯†åˆ«ç»“æœ
            - layout: ç‰ˆé¢åˆ†æç»“æœ
            - metadata: å…ƒæ•°æ®
        """
        logger.info(f"ğŸš€ å¼€å§‹åŠ è½½ PDF: {pdf_path}")
        
        if not Path(pdf_path).exists():
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
            return {}
        
        result = {
            "text": "",
            "tables": [],
            "ocr_results": {},
            "layout": {},
            "metadata": {
                "file_path": pdf_path,
                "file_name": Path(pdf_path).name
            }
        }
        
        # 1. ç‰ˆé¢åˆ†æï¼ˆè·å–ç»“æ„åŒ–æ–‡æœ¬ï¼‰
        if self.enable_layout_analysis:
            logger.info("ğŸ“Š æ‰§è¡Œç‰ˆé¢åˆ†æ...")
            layout_result = self.layout_analyzer.analyze_layout(pdf_path)
            result["layout"] = layout_result
            
            # æå–æŒ‰é˜…è¯»é¡ºåºæ’åˆ—çš„æ–‡æœ¬
            blocks = layout_result.get("blocks", [])
            text_parts = []
            for block in blocks:
                if block.block_type in ["title", "body"]:
                    text_parts.append(block.text)
            
            result["text"] = "\n\n".join(text_parts)
            logger.info(f"âœ… æå–æ–‡æœ¬ {len(result['text'])} å­—ç¬¦")
        
        # 2. è¡¨æ ¼æå–
        if self.enable_table_extraction:
            logger.info("ğŸ“‹ æ‰§è¡Œè¡¨æ ¼æå–...")
            table_results = self.table_extractor.extract_all(pdf_path)
            
            # åˆå¹¶æ‰€æœ‰æ–¹æ³•æå–çš„è¡¨æ ¼
            all_tables = []
            for method, tables in table_results.items():
                all_tables.extend(tables)
            
            result["tables"] = all_tables
            logger.info(f"âœ… æå– {len(all_tables)} ä¸ªè¡¨æ ¼")
        
        # 3. OCR è¯†åˆ«ï¼ˆé’ˆå¯¹æ‰«æç‰ˆæˆ–å›¾ç‰‡ï¼‰
        if self.enable_ocr:
            logger.info("ğŸ” æ‰§è¡Œ OCR è¯†åˆ«...")
            ocr_results = self.ocr.process_pdf(pdf_path, confidence_threshold=0.6)
            result["ocr_results"] = ocr_results
            
            # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨ OCR ç»“æœ
            if not result["text"].strip() and ocr_results:
                ocr_text_parts = []
                for page_num in sorted(ocr_results.keys()):
                    ocr_text_parts.extend(ocr_results[page_num])
                result["text"] = "\n".join(ocr_text_parts)
                logger.info(f"âœ… ä½¿ç”¨ OCR æ–‡æœ¬ {len(result['text'])} å­—ç¬¦")
        
        logger.info(f"ğŸ‰ PDF åŠ è½½å®Œæˆ")
        return result
    
    def load_and_split(self, 
                      pdf_path: str, 
                      chunk_size: int = 1000, 
                      chunk_overlap: int = 200) -> List[Dict]:
        """
        åŠ è½½ PDF å¹¶åˆ†å—ï¼ˆé€‚ç”¨äº RAG ç³»ç»Ÿï¼‰
        
        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            chunk_size: å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            chunk_overlap: å—é‡å å¤§å°
            
        Returns:
            æ–‡æœ¬å—åˆ—è¡¨ï¼Œæ¯ä¸ªå—åŒ…å« text å’Œ metadata
        """
        # åŠ è½½ PDF
        result = self.load(pdf_path)
        
        if not result.get("text"):
            logger.warning("âš ï¸ æœªæå–åˆ°æ–‡æœ¬å†…å®¹")
            return []
        
        # ç®€å•åˆ†å—ï¼ˆæŒ‰å­—ç¬¦æ•°ï¼‰
        text = result["text"]
        chunks = []
        
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunk_text = text[start:end]
            
            chunks.append({
                "text": chunk_text,
                "metadata": {
                    "source": result["metadata"]["file_name"],
                    "chunk_id": len(chunks),
                    "start_char": start,
                    "end_char": end
                }
            })
            
            start = end - chunk_overlap
        
        logger.info(f"âœ… åˆ†å—å®Œæˆï¼Œå…± {len(chunks)} ä¸ªå—")
        return chunks
    
    def batch_load(self, pdf_paths: List[str]) -> List[Dict]:
        """
        æ‰¹é‡åŠ è½½å¤šä¸ª PDF æ–‡ä»¶
        
        Args:
            pdf_paths: PDF æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            è§£æç»“æœåˆ—è¡¨
        """
        results = []
        
        for i, pdf_path in enumerate(pdf_paths):
            logger.info(f"ğŸ“‚ å¤„ç†æ–‡ä»¶ {i+1}/{len(pdf_paths)}: {pdf_path}")
            try:
                result = self.load(pdf_path)
                results.append(result)
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
                continue
        
        logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ {len(results)}/{len(pdf_paths)} ä¸ªæ–‡ä»¶")
        return results
    
    def export_results(self, result: Dict, output_dir: str):
        """
        å¯¼å‡ºè§£æç»“æœåˆ°æ–‡ä»¶
        
        Args:
            result: è§£æç»“æœ
            output_dir: è¾“å‡ºç›®å½•
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        file_name = result["metadata"]["file_name"].replace(".pdf", "")
        
        # 1. å¯¼å‡ºæ–‡æœ¬
        text_file = output_path / f"{file_name}_text.txt"
        with open(text_file, 'w', encoding='utf-8') as f:
            f.write(result["text"])
        logger.info(f"ğŸ’¾ æ–‡æœ¬å·²ä¿å­˜: {text_file}")
        
        # 2. å¯¼å‡ºè¡¨æ ¼
        if result["tables"]:
            self.table_extractor.save_tables(
                result["tables"], 
                str(output_path / "tables"),
                prefix=file_name
            )
        
        # 3. å¯¼å‡º OCR ç»“æœ
        if result["ocr_results"]:
            ocr_file = output_path / f"{file_name}_ocr.txt"
            self.ocr.export_ocr_results(result["ocr_results"], str(ocr_file))
        
        # 4. å¯¼å‡ºç‰ˆé¢åˆ†æç»“æœ
        if result["layout"] and result["layout"].get("blocks"):
            layout_file = output_path / f"{file_name}_layout.txt"
            self.layout_analyzer.export_to_text(result["layout"]["blocks"], str(layout_file))
        
        logger.info(f"âœ… æ‰€æœ‰ç»“æœå·²å¯¼å‡ºåˆ°: {output_dir}")


def compare_with_basic_loader(pdf_path: str):
    """
    å¯¹æ¯”åŸºç¡€åŠ è½½å™¨å’Œé«˜çº§åŠ è½½å™¨çš„æ•ˆæœ
    
    Args:
        pdf_path: PDF æ–‡ä»¶è·¯å¾„
    """
    from langchain_community.document_loaders import PyPDFLoader
    
    print("\n" + "="*60)
    print("ğŸ“Š åŸºç¡€åŠ è½½å™¨ vs é«˜çº§åŠ è½½å™¨å¯¹æ¯”")
    print("="*60)
    
    # åŸºç¡€åŠ è½½å™¨
    print("\n1ï¸âƒ£ åŸºç¡€åŠ è½½å™¨ï¼ˆPyPDFLoaderï¼‰:")
    try:
        basic_loader = PyPDFLoader(pdf_path)
        basic_docs = basic_loader.load()
        basic_text = "\n".join([doc.page_content for doc in basic_docs])
        print(f"   æå–æ–‡æœ¬: {len(basic_text)} å­—ç¬¦")
        print(f"   æ–‡æ¡£æ•°: {len(basic_docs)}")
        print(f"   è¡¨æ ¼æå–: âŒ ä¸æ”¯æŒ")
        print(f"   OCR: âŒ ä¸æ”¯æŒ")
        print(f"   ç‰ˆé¢åˆ†æ: âŒ ä¸æ”¯æŒ")
    except Exception as e:
        print(f"   âŒ åŠ è½½å¤±è´¥: {e}")
    
    # é«˜çº§åŠ è½½å™¨
    print("\n2ï¸âƒ£ é«˜çº§åŠ è½½å™¨ï¼ˆAdvancedPDFLoaderï¼‰:")
    try:
        advanced_loader = AdvancedPDFLoader()
        result = advanced_loader.load(pdf_path)
        print(f"   æå–æ–‡æœ¬: {len(result['text'])} å­—ç¬¦")
        print(f"   è¡¨æ ¼æå–: âœ… æå– {len(result['tables'])} ä¸ªè¡¨æ ¼")
        print(f"   OCR: âœ… è¯†åˆ« {len(result['ocr_results'])} é¡µå›¾ç‰‡")
        print(f"   ç‰ˆé¢åˆ†æ: âœ… æ£€æµ‹ {result['layout']['summary'].get('max_columns', 0)} åˆ—å¸ƒå±€")
        
        print(f"\nğŸ“ˆ æå‡æ•ˆæœ:")
        if basic_text:
            improvement = (len(result['text']) - len(basic_text)) / len(basic_text) * 100
            print(f"   æ–‡æœ¬æå–é‡æå‡: {improvement:.1f}%")
        print(f"   é¢å¤–åŠŸèƒ½: è¡¨æ ¼ç»“æ„åŒ–ã€å›¾ç‰‡æ–‡å­—è¯†åˆ«ã€ç‰ˆé¢ç†è§£")
    except Exception as e:
        print(f"   âŒ åŠ è½½å¤±è´¥: {e}")


def demo():
    """æ¼”ç¤ºé«˜çº§åŠ è½½å™¨åŠŸèƒ½"""
    # åˆ›å»ºåŠ è½½å™¨å®ä¾‹
    loader = AdvancedPDFLoader(
        enable_table_extraction=True,
        enable_ocr=True,
        enable_layout_analysis=True,
        ocr_lang='ch'
    )
    
    # æµ‹è¯•æ–‡ä»¶
    test_files = [
        "test_data/complex_table.pdf",
        "test_data/scanned_doc.pdf",
        "test_data/multi_column.pdf"
    ]
    
    # æ£€æŸ¥å¹¶å¤„ç†å­˜åœ¨çš„æ–‡ä»¶
    existing_files = [f for f in test_files if Path(f).exists()]
    
    if not existing_files:
        print("âš ï¸ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å‡†å¤‡ä»¥ä¸‹æ–‡ä»¶:")
        for f in test_files:
            print(f"   - {f}")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(existing_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
    
    # å¤„ç†ç¬¬ä¸€ä¸ªæ–‡ä»¶
    test_file = existing_files[0]
    print(f"\nğŸ¯ å¤„ç†: {test_file}")
    
    # å¯¹æ¯”åŸºç¡€åŠ è½½å™¨
    try:
        compare_with_basic_loader(test_file)
    except:
        pass
    
    # åŠ è½½å¹¶å¯¼å‡ºç»“æœ
    result = loader.load(test_file)
    loader.export_results(result, "output/advanced_results")
    
    # åˆ†å—å¤„ç†ï¼ˆRAG ç”¨ï¼‰
    chunks = loader.load_and_split(test_file, chunk_size=500, chunk_overlap=100)
    print(f"\nâœ… åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªæ–‡æœ¬å—")
    print(f"   å—å¤§å°: 500 å­—ç¬¦")
    print(f"   é‡å : 100 å­—ç¬¦")


if __name__ == "__main__":
    demo()